{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6505a7ad",
   "metadata": {},
   "source": [
    "## What is MLFlow and its Components\n",
    "\n",
    "MLFLow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. MLFLow currently offers four components:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745f450",
   "metadata": {},
   "source": [
    "<img src=\"mlflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5a6b9",
   "metadata": {},
   "source": [
    "#### Make sure python is used from your newly created environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd81db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\Envs\\mlflow\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3caf80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ff2b8",
   "metadata": {},
   "source": [
    "### Create functions for all the steps involved in complete model training lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0efd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9e53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5611082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
       "1   53   technician  married            unknown       no      no   no   \n",
       "2   28   management   single  university.degree       no     yes   no   \n",
       "3   39     services  married        high.school       no      no   no   \n",
       "4   55      retired  married           basic.4y       no     yes   no   \n",
       "\n",
       "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
       "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
       "2  cellular   jun         thu  ...         3      6         2      success   \n",
       "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
       "4  cellular   aug         fri  ...         1      3         1      success   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
       "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
       "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
       "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
       "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data('https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdca67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    print(\"na values available in data \\n\")\n",
    "    print(data.isna().sum())\n",
    "    data = data.dropna()\n",
    "    print(\"after droping na values \\n\")\n",
    "    print(data.isna().sum())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d378c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "    data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
    "    data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])\n",
    "    \n",
    "    cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "    for var in cat_vars:\n",
    "        cat_list='var'+'_'+var\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        data1=data.join(cat_list)\n",
    "        data=data1\n",
    "\n",
    "    cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "    data_vars=data.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "    \n",
    "    final_data=data[to_keep]\n",
    "    \n",
    "    \n",
    "    final_data.columns = final_data.columns.str.replace('.','_')\n",
    "    final_data.columns = final_data.columns.str.replace(' ','_')\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f78530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(final_data):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = final_data.loc[:, final_data.columns != 'y']\n",
    "    y = final_data.loc[:, final_data.columns == 'y']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify = y, random_state=47)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb6095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling_target_class(X_train, y_train):\n",
    "    ### Over-sampling using SMOTE \n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    os = SMOTE(random_state=0)\n",
    "\n",
    "    columns = X_train.columns\n",
    "    os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "\n",
    "    os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "    os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "    # we can Check the numbers of our data\n",
    "    print(\"length of oversampled data is \",len(os_data_X))\n",
    "    print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "    print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "    print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "    print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))\n",
    "    \n",
    "    X_train = os_data_X\n",
    "    y_train = os_data_y['y']\n",
    " \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c85667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_basic_classifier(X_train,y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=101)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3c96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a475cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob_on_test_data(model,X_test):\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ccc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, y_pred_prob):\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    entropy = log_loss(y_true, y_pred_prob)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca1aeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_auc_plot(clf, X_data, y_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "    metrics.plot_roc_curve(clf, X_data, y_data) \n",
    "    plt.savefig('roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db16c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_plot(clf, X_test, y_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    plot_confusion_matrix(clf, X_test, y_test)\n",
    "    plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aec48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning(X_train, y_train):\n",
    "    # define random parameters grid\n",
    "    n_estimators = [5,21,51,101] # number of trees in the random forest\n",
    "    max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "    max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "    min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "    min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "    bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "                    'bootstrap': bootstrap\n",
    "                  }\n",
    "    \n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier()\n",
    "    model_tuning = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid,\n",
    "                   n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "    model_tuning.fit(X_train, y_train)\n",
    "\n",
    "    print ('Random grid: ', random_grid, '\\n')\n",
    "    # print the best parameters\n",
    "    print ('Best Parameters: ', model_tuning.best_params_, ' \\n')\n",
    "\n",
    "    best_params = model_tuning.best_params_\n",
    "    \n",
    "    n_estimators = best_params['n_estimators']\n",
    "    min_samples_split = best_params['min_samples_split']\n",
    "    min_samples_leaf = best_params['min_samples_leaf']\n",
    "    max_features = best_params['max_features']\n",
    "    max_depth = best_params['max_depth']\n",
    "    bootstrap = best_params['bootstrap']\n",
    "    \n",
    "    model_tuned = RandomForestClassifier(n_estimators = n_estimators, min_samples_split = min_samples_split,\n",
    "                                         min_samples_leaf= min_samples_leaf, max_features = max_features,\n",
    "                                         max_depth= max_depth, bootstrap=bootstrap) \n",
    "    model_tuned.fit( X_train, y_train)\n",
    "    return model_tuned,best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acce9f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_data('https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "376d0587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na values available in data \n",
      "\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "after droping na values \n",
      "\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = data_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e4a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = preprocessing(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bbb6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da133cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  51166\n",
      "Number of no subscription in oversampled data 25583\n",
      "Number of subscription 25583\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = over_sampling_target_class(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c0e3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training_basic_classifier(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b485e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_on_test_data(model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55d29fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e4fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = predict_prob_on_test_data(model,X_test) #model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f7765b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99009901, 0.00990099],\n",
       "       [0.99009901, 0.00990099],\n",
       "       [0.96039604, 0.03960396],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [0.72277228, 0.27722772],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceef3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bdeda22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.91, 'precision': 0.63, 'recall': 0.54, 'entropy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ff3c7fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'plot_roc_curve'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_roc_auc_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m, in \u001b[0;36mcreate_roc_auc_plot\u001b[1;34m(clf, X_data, y_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_roc_curve\u001b[49m(clf, X_data, y_data) \n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc_curve.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'plot_roc_curve'"
     ]
    }
   ],
   "source": [
    "create_roc_auc_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ce51f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_confusion_matrix_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m, in \u001b[0;36mcreate_confusion_matrix_plot\u001b[1;34m(clf, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_confusion_matrix_plot\u001b[39m(clf, X_test, y_test):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_confusion_matrix\n\u001b[0;32m      4\u001b[0m     plot_confusion_matrix(clf, X_test, y_test)\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "create_confusion_matrix_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc429fce",
   "metadata": {},
   "source": [
    "### MLFlow work Starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5756180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.91, 'precision': 0.63, 'recall': 0.54, 'entropy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"basic_classifier\" ##basic classifier\n",
    "run_name=\"term_deposit\"\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)\n",
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a00fb",
   "metadata": {},
   "source": [
    "### Function to create an experiment in MLFlow and log parameters, metrics and artifacts files like images etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26f2c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name,run_name, run_metrics,model, confusion_matrix_path = None, \n",
    "                      roc_auc_plot_path = None, run_params=None):\n",
    "    import mlflow\n",
    "    #mlflow.set_tracking_uri(\"http://localhost:5000\") #uncomment this line if you want to use any database like sqlite as backend storage for model\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_materix')\n",
    "            \n",
    "        if not roc_auc_plot_path == None:\n",
    "            mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"Random Forest\")\n",
    "        mlflow.set_tags({\"tag2\":\"Randomized Search CV\", \"tag3\":\"Production\"})\n",
    "            \n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcd0c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - term_deposit is logged to Experiment - basic_classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model,'confusion_matrix.png', 'roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5b47c",
   "metadata": {},
   "source": [
    "### Create another experiment after tuning hyperparameters and log the best set of parameters for which model gives the optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a0d0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "235 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "157 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "78 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.92647648 0.93384538 0.93196922        nan        nan        nan\n",
      "        nan 0.93679666 0.93750013 0.93593668 0.93751948        nan\n",
      "        nan 0.93505711 0.93607317 0.93665981        nan 0.93390372\n",
      "        nan 0.92882259 0.93810598        nan        nan        nan\n",
      " 0.93605412 0.93753922 0.93642529 0.93763662        nan        nan\n",
      "        nan        nan        nan 0.93363006        nan        nan\n",
      "        nan 0.92917423        nan        nan 0.93275097        nan\n",
      " 0.93615142 0.93574111 0.93448993 0.93902463        nan        nan\n",
      " 0.93261425 0.93787153        nan        nan 0.93822333 0.93751989\n",
      " 0.93687484        nan        nan 0.93783246        nan        nan\n",
      "        nan        nan 0.93638651        nan 0.93679666        nan\n",
      " 0.93730477        nan 0.935917          nan 0.93867246 0.93402149\n",
      " 0.93834051        nan 0.93634727 0.93666014 0.93116775 0.92428722\n",
      " 0.9377347         nan 0.93317982 0.9365817  0.93400221        nan\n",
      " 0.93736346        nan        nan        nan        nan        nan\n",
      " 0.93763686 0.93716806 0.93779312 0.93793008        nan 0.93691351\n",
      "        nan 0.93734396 0.93669889        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random grid:  {'n_estimators': [5, 21, 51, 101], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120], 'min_samples_split': [2, 6, 10], 'min_samples_leaf': [1, 3, 4], 'bootstrap': [True, False]} \n",
      "\n",
      "Best Parameters:  {'n_estimators': 51, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 70, 'bootstrap': True}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment_name = \"optimized model\"\n",
    "run_name=\"Random_Search_CV_Tuned_Model\"\n",
    "model_tuned,best_params = hyper_parameter_tuning(X_train, y_train)\n",
    "run_params = best_params\n",
    "\n",
    "y_pred = predict_on_test_data(model_tuned,X_test) #will return the predicted class\n",
    "y_pred_prob = predict_prob_on_test_data(model_tuned,X_test) #model.predict_proba(X_test)\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "163fd982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91, 'precision': 0.61, 'recall': 0.56, 'entropy': 0.2}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d8bafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators 51\n",
      "min_samples_split 6\n",
      "min_samples_leaf 1\n",
      "max_features sqrt\n",
      "max_depth 70\n",
      "bootstrap True\n"
     ]
    }
   ],
   "source": [
    "for param in run_params:\n",
    "    print(param, run_params[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f520e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/02 16:15:16 INFO mlflow.tracking.fluent: Experiment with name 'optimized model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Random_Search_CV_Tuned_Model is logged to Experiment - optimized model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saura\\Envs\\mlflow\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model_tuned,'confusion_matrix.png', 'roc_auc_curve.png',run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dadd7",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "Using MLFlow\n",
    "* How deploy models from model registry\n",
    "* Model serving both batch serving and online serving\n",
    "* MLFlow pipelines\n",
    "* Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7af37",
   "metadata": {},
   "source": [
    "# Thank You "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
